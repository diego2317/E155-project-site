[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Robot Site",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "deliverables/proposal.html",
    "href": "deliverables/proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "The inspiration for this project came from a project Diego completed in a robotics class during his junior year of high school. He built an extremely rudimentary line-follower robot using an Arduino and two IR sensors. The goal of this project is to once again build a line-follower robot, this time interfacing an OV7670 camera with an UPduino iCE40 UP5K FPGA board (“the FPGA”) and a STM32L432KC microcontroller (“the MCU”). The FPGA will interface with the OV7670 to detect the line and send the resultant information to the MCU for robot control."
  },
  {
    "objectID": "deliverables/proposal.html#project-design-overview",
    "href": "deliverables/proposal.html#project-design-overview",
    "title": "Project Proposal",
    "section": "",
    "text": "The inspiration for this project came from a project Diego completed in a robotics class during his junior year of high school. He built an extremely rudimentary line-follower robot using an Arduino and two IR sensors. The goal of this project is to once again build a line-follower robot, this time interfacing an OV7670 camera with an UPduino iCE40 UP5K FPGA board (“the FPGA”) and a STM32L432KC microcontroller (“the MCU”). The FPGA will interface with the OV7670 to detect the line and send the resultant information to the MCU for robot control."
  },
  {
    "objectID": "deliverables/proposal.html#specifications",
    "href": "deliverables/proposal.html#specifications",
    "title": "Project Proposal",
    "section": "Specifications",
    "text": "Specifications\n\nRobot follows a black line on white paper\nRobot doesn’t move if no line is detected\nRobot uses camera as vision interface\nFPGA receives pixel data from OV7670\nFPGA sends masked pixel data to MCU over a communication interface\nMCU configures registers on OV7670 over SCCB/I2C interface\nMCU is able to receive full frames from FPGA"
  },
  {
    "objectID": "deliverables/proposal.html#design-details",
    "href": "deliverables/proposal.html#design-details",
    "title": "Project Proposal",
    "section": "Design Details",
    "text": "Design Details\n\nMCU Design & New Functionality\nThe MCU will have four critical functions. It needs to configure the OV7670 over the SCCB interface, send the FPGA a signal to drive XCLK, read bit-masked frames from the FPGA over SPI, and control the position of the robot along the line based on the data from the frames. The new functionality on the MCU will be the SCCB peripheral and the implementation of DMA to enable high-speed SPI reads.\n\n\nFPGA Design & New Functionality\nThe FPGA has several critical functions, notably to: drive XCLK at 24MHz, read & process pixel data from the OV7670, and communicate that data to the MCU over SPI. In order to send pixel data to the MCU, a double SPRAM buffer will be implemented. The new functionality on the FPGA will be the SPRAM buffer and SPI communication.\n\n\nNew Hardware\nThe main piece of new hardware being integrated is the OV7670 camera module.\n\n\nRiskiest Element\nUsing the MCU to configure the OV7670 is definitely the riskiest element of the project. Although the SCCB interface is based on I2C, literature review indicated that the I2C interface on the MCU would not be able to configure the camera. So, the team will need to bit-bang an SCCB interface. The team will attempt to mitigate risk by consulting examples available online."
  },
  {
    "objectID": "deliverables/proposal.html#technical-documentation",
    "href": "deliverables/proposal.html#technical-documentation",
    "title": "Project Proposal",
    "section": "Technical Documentation",
    "text": "Technical Documentation\n\nBlock Diagram\n\n\n\n\n\n\nFigure 1: Block Diagram\n\n\n\nThe block diagram in Figure 1 provides a general outline of the protocols and interfaces that will be utilized in the project.\n\n\nPerformance Calculations\n\nSPI Performance\nAccording to the datasheet of the STM32, the maximum frequency of SCK when configured in master/receiver full-duplex mode is 40MHz when VDD ∈ [2.7, 3.6]. A 40 MHz SCK results in a maximum throughput of approximately 5 MB/s. Since each frame will be 9.6kB, each frame can be read in approximately 1.92ms. For a frame rate of 30 fps, the FPGA will produce a frame every 33.3ms. This means that there will be approximately 31.3 ms for robot control.\n\n\nLUT Usage\nThese are meant to be preliminary order-of-magnitude calculations. The FPGA used (Lattice iCE40 UP5K) has hardware SPI support, so the SPI interface requires no LUTs.\n\nAssuming 8 8-bit counters for things like write address, read address, frame ID, etc, we have 64 LUTs\nFor bit masking, a comparator can be used. If we compare on all 8 bits of the Y (using a YUV pixel format), we’d need 8 LUTs\nTo encode the double buffer, we’d need enough LUTs for state. If we assume 20 states (massive overestimate), we’d at most 100 LUTs.\nTo account for any other random parts of the design, we’ll add in 200 extra LUTs\n\nThis only brings us &lt;400 LUTs. Although we likely missed aspects of the design, it is exceedingly unlikely that we come close to even 40% LUT resource usage on the FPGA, as the FPGA has ~5000 LUTs available\n\n\nSPRAM Buffer Sizing\nAccording to the datasheet for the FPGA, we have 1 MB of SPRAM available. A 1-bit mask of a QVGA image only requires 9.6kB of space. So, we have more than enough space in SPRAM."
  },
  {
    "objectID": "deliverables/proposal.html#project-management",
    "href": "deliverables/proposal.html#project-management",
    "title": "Project Proposal",
    "section": "Project Management",
    "text": "Project Management\n\nBill of Materials\n\n\n\n\n\n\n\n\n\n\nItem\nPart Number\nQuantity\nPrice\nSource\n\n\n\n\nCamera Module\nOV7670\n1\n$8-12 (+ shipping)\nAmazon\n\n\nPotentiometer (Threshold control)\n10 k \\(\\Omega\\) Linear Pot\n1\nStockroom\nStockroom\n\n\nDC Motors\nTT Gear Motor (3-6 V)\n2\nStockroom\nStockroom\n\n\nMotor Driver\nL298N\n1\n$3-6\nAmazon/Stockroom\n\n\nRobot Chassis Kit\nN/A\n1\nStockroom\nStockroom\n\n\n\n\n\nProject Timeline\n\n\n\nTask(s)\nDate\n\n\n\n\nFinish proposal\n10/20/25\n\n\nStart Project\n10/21/25\n\n\nPrepare slides for design review\n11/7/25\n\n\nFinish Midpoint Report & Demo\n11/16/25\n\n\nFinal Checkoff\n12/5/25\n\n\nFinal Report Due\n12/7/25\n\n\nDemo Day\n12/8/25\n\n\n\n\n\nTask Delegation\n\n\n\nDiego\nAabhas\n\n\n\n\nStart MCU Code\nStart FPGA Code\n\n\nCheck FPGA Code\nCheck MCU Code\n\n\nDecide MCU task scheduling\nDecide MCU task scheduling\n\n\nWrite robot control code\nCheck robot control code\n\n\nCheck robot\nAssemble robot\n\n\nWrite verification\nWrite verification\n\n\nWrite documentation\nWrite documentation\n\n\n\nOur aim is to work together as much as possible, so that both team members are full owners of the project."
  },
  {
    "objectID": "deliverables/checkoff.html",
    "href": "deliverables/checkoff.html",
    "title": "Project Final Checkoff Report",
    "section": "",
    "text": "One Pager\nAs a reminder, the overall specs for the project are listed below. All specs were completed!\n\nRobot follows a black line on white paper\n\nThis spec essentially encapsulates the project, and was confirmed through visual observation of the final robot.\n\nRobot doesn’t move if both cameras see a black line\n\nThis spec was confirmed by observing the performance of the robot.\n\nRobot uses camera as vision interface\n\nThe only sensors being used to control the robot are cameras. Due to difficulties encountered with camera noise, two cameras are used to control the robot, with control determined by the amount of black pixels in each image.\n\nFPGA receives pixel data from OV7670\n\nThe FPGA receiving pixel data from the OV7670 was confirmed through the performance of our system. It was difficult to verify the design worked in the real world until we had our MCU configured to receive data from the FPGA, but once we did, we were able to confirm that the MCU received changing pixel data from the FPGA, which told us that the FPGA was receiving pixel data from the OV7670. Otherwise, we wouldn’t be able to see the difference between black and white!\n\nFPGA sends masked frame data to MCU over a communication interface\n\nThe FPGA sends frames to the MCU over a modified SPI bus, where the MCU is configured as the master. Because the communication between the FPGA and MCU is one-directional, only the COPI and CLK lines were connected. The MCU recevies a signal from the FPGA indicating that a frame is ready to be sent. Once it receives that signal, it sends the SPI CLK to the FPGA, and the FPGA shifts data out over that clock.\n\nMCU configures registers on OV7670 over SCCB/I2C interface\n\nWe were able to confirm that the MCU configures registers on the OV7670 early on in the project. SCCB effectively acts as I2C, but is named differently for licensing reasons. Using the MCU’s I2C peripheral, we were able to write to specific registers and then read back those registers to confirm succesful writes.\n\nMCU is able to receive full frames from FPGA\n\nWe know that the MCU receives full frames from the FPGA (within some tolerance), because the control loop includes a condition that the MCU doesn’t control the motor it’s connected to unless it receives at least 76000 pixels from the FPGA. This is actually a critical function for robot control, as if we controlled off partial frames, the robot’s performance would likely suffer.\n\n\n\n\nSchematic\nThe final system schematic representing all the connections between the different peripherals in the system can be seen below.\n\n\n\nSchematic\n\n\n\n\nBlock Diagram"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "deliverables/midpoint.html",
    "href": "deliverables/midpoint.html",
    "title": "Project Midpoint Report",
    "section": "",
    "text": "As of the midpoint report being written, the team has accomplished the following: - Configuration of the OV7670 camera module through register writes from the MCU over an I2C interface - Pixel data capture from the OV7670 camera module on the FPGA - Streaming bit-masked pixel data from the FPGA to the MCU over a 1-directional parallel bus - Full bit-masked frame capture and display on the MCU using GPIO polling\nAs a reminder, the overall specs for the project are listed below, with the already-completed specs checked off.\n\nRobot follows a black line on white paper\nRobot doesn’t move if both cameras see a black line\nRobot uses camera as vision interface\nFPGA receives pixel data from OV7670\nFPGA sends masked frame data to MCU over a communication interface\nMCU configures registers on OV7670 over SCCB/I2C interface\nMCU is able to receive full frames from FPGA\n\nAt this point in the project, the team believes that the riskiest elements have been completed, as the camera is now able to be configured, and camera data is captured by the FPGA, analyzed, and sent to the MCU.\n\n\n\nPrior to beginning work on the project, the team identified the riskiest element as configuring the OV7670 CMOS camera using the MCU over the SCCB interface. This was because there weren’t many examples on how to implement this interface, which created the possibility of the team needing to bit-bang our own SCCB interface, which is similar to I2C but has some quite relevant differences, the main one being that the SCCB controller on the OV7670 sends a “don’t care” bit as the 9th bit, while the I2C interface on the MCU expects an “ACK” bit to be sent from the OV7670 to acknowledge data. However, the team was succesfully able to configure the OV7670 using the I2C peripheral on the MCU.\n\n\n\nNow that the team is receiving full frames on the MCU, the remaining work can be broken into three phases.\n\n\nCurrently, the FPGA sends the MCU a pixel as soon as it finishes bit-masking it. For the final design, the goal will be to implement an asynchronous FIFO using the SPRAM on the MCU, so that full frames can be read much quicker, leaving time for robot control.\n\n\n\nAlthough the team has purchased a robot kit, some design considerations need to be taken into account, as the camera needs to be mounted on the robot along with the rest of the parts. The camera module will likely need a light mounted near it to illuminate the track, which would also require the integration of a lens hood.\n\n\n\nOnce the peripherals are fully integrated and mounted on the robot chassis, the team expects that there will be significant work left to do on tuning the control system on the MCU, as well as tuning camera exposure settings to improve line recognition. Also, the field of view of the camera will need to be determined, and the camera will potentially need to be focused."
  },
  {
    "objectID": "deliverables/midpoint.html#progress-report",
    "href": "deliverables/midpoint.html#progress-report",
    "title": "Project Midpoint Report",
    "section": "",
    "text": "As of the midpoint report being written, the team has accomplished the following: - Configuration of the OV7670 camera module through register writes from the MCU over an I2C interface - Pixel data capture from the OV7670 camera module on the FPGA - Streaming bit-masked pixel data from the FPGA to the MCU over a 1-directional parallel bus - Full bit-masked frame capture and display on the MCU using GPIO polling\nAs a reminder, the overall specs for the project are listed below, with the already-completed specs checked off.\n\nRobot follows a black line on white paper\nRobot doesn’t move if both cameras see a black line\nRobot uses camera as vision interface\nFPGA receives pixel data from OV7670\nFPGA sends masked frame data to MCU over a communication interface\nMCU configures registers on OV7670 over SCCB/I2C interface\nMCU is able to receive full frames from FPGA\n\nAt this point in the project, the team believes that the riskiest elements have been completed, as the camera is now able to be configured, and camera data is captured by the FPGA, analyzed, and sent to the MCU.\n\n\n\nPrior to beginning work on the project, the team identified the riskiest element as configuring the OV7670 CMOS camera using the MCU over the SCCB interface. This was because there weren’t many examples on how to implement this interface, which created the possibility of the team needing to bit-bang our own SCCB interface, which is similar to I2C but has some quite relevant differences, the main one being that the SCCB controller on the OV7670 sends a “don’t care” bit as the 9th bit, while the I2C interface on the MCU expects an “ACK” bit to be sent from the OV7670 to acknowledge data. However, the team was succesfully able to configure the OV7670 using the I2C peripheral on the MCU.\n\n\n\nNow that the team is receiving full frames on the MCU, the remaining work can be broken into three phases.\n\n\nCurrently, the FPGA sends the MCU a pixel as soon as it finishes bit-masking it. For the final design, the goal will be to implement an asynchronous FIFO using the SPRAM on the MCU, so that full frames can be read much quicker, leaving time for robot control.\n\n\n\nAlthough the team has purchased a robot kit, some design considerations need to be taken into account, as the camera needs to be mounted on the robot along with the rest of the parts. The camera module will likely need a light mounted near it to illuminate the track, which would also require the integration of a lens hood.\n\n\n\nOnce the peripherals are fully integrated and mounted on the robot chassis, the team expects that there will be significant work left to do on tuning the control system on the MCU, as well as tuning camera exposure settings to improve line recognition. Also, the field of view of the camera will need to be determined, and the camera will potentially need to be focused."
  },
  {
    "objectID": "deliverables/midpoint.html#documentation",
    "href": "deliverables/midpoint.html#documentation",
    "title": "Project Midpoint Report",
    "section": "Documentation",
    "text": "Documentation\n\nSchematic\nThe team has created a semi-finalized schematic representing all the connections between the different peripherals in the system, which can be seen below.\n\n\n\nSchematic\n\n\n\n\nBlock Diagram\nThe block diagram has been updated slightly since the proposal to reflect some of the changes in the design methodology.\n\n\n\nBlock Diagram\n\n\n\n\nMCU Routine Overview\nCurrently, the MCU uses a super loop and polling to capture frame data. Eventually, the hope is to use FreeRTOS, although that is not a spec for the project because it’s a stretch goal. The current routine involves waiting for the frame-active pin to go high, then reading pixel data on the falling edge of PCLK when the pixel data is valid. The pixel data is currently stored in RAM on the MCU, as each frame is only 9.6kB, so one frame can be stored in RAM at a time. Once the asynchronous FIFO has been implemented on the FPGA, the entire frame will be streamed to the MCU, so the MCU will not need to check whether the data is valid. When combined with DMA for frame capture, this will allow for much faster frame reads and will decrease the amount of dropped frames.\n\n\nFPGA Code\n\n\n\n\n\n\n(Click to expand)\n\n\n\n\n\n\n\n\n\n\n\nMCU Code\n\n\n\n\n\n\n(Click to expand)"
  },
  {
    "objectID": "deliverables.html",
    "href": "deliverables.html",
    "title": "Early Deliverables",
    "section": "",
    "text": "Project Final Checkoff Report\n\n\nProject Final Checkoff Report\n\n\n\n\n\nDec 3, 2025\n\n\nAabhas Senapati & Diego Weiss\n\n\n\n\n\n\n\n\n\n\n\n\nProject Midpoint Report\n\n\nProject Midpoint Report\n\n\n\n\n\nNov 20, 2025\n\n\nAabhas Senapati & Diego Weiss\n\n\n\n\n\n\n\n\n\n\n\n\nProject Proposal\n\n\nProject Proposal\n\n\n\n\n\nOct 15, 2025\n\n\nAabhas Senapati & Diego Weiss\n\n\n\n\n\nNo matching items"
  }
]