[
  {
    "objectID": "mcu.html",
    "href": "mcu.html",
    "title": "MCU Overview",
    "section": "",
    "text": "General Overview\nThe project uses two MCUs, each of which is independent from the other. The MCUs purpose is to read bit-masked pixel data from an FPGA over SPI in frame packets, determine the number of black pixels in the frame, and control a motor based on that number. Each MCU also handles the configuration of an OV7670 camera over I2C.\n\n\nOV7670 Configuration\nThe OV7670 Camera module supports register reads and writes over a communication protocol called SCCB, which is very similar to I2C except it doesn’t support multi-byte transmission & sends a don’t care (X) instead of an ACK/NACK at the end of each transmission. By adding pull-up resistors and limiting ourselves to single-byte transmissions, we were able to use the I2C peripheral on the MCU to configure registers on the OV7670, which was very convenient. We were then able to configure the OV7670 in QVGA YUV mode, giving us a resolution of 320x240 pixels.\nThe biggest sticking point with the camera was configuring it to have deterministic behavior. For a long time, we were disabling autoexposure, but the camera still wasn’t acting deterministically. The key is to disable autoexposure first, the enable exposure setting by setting specific registers, which can be found in the OV7670 datasheet & implementation guide. We unfortunately discovered this 24 hours before checkoff, which resulted in us having to change our plan for our control system.\n\n\nRobot Control\nThe plan was to scan the bit-masked frame to find the black line’s left and right edges, take their midpoint, and use this to compute the line’s horizontal position error relative to the image center. To get the line angle, the MCU would compare midpoints of every row and compute the slope/angle of the line segment connecting them. However, the aforementioned delays in configuring the OV7670 meant that this plan had to be scrapped. We decided to transition to a control system akin to what’s used in line-following robots that use two IR sensors to detect a line. This required the use of two boards, one to control a camera and motor on each side. The robot is then controlled by having each MCU read a frame from the FPGA, compare the number of black pixels to a predefined threshold, and then having it drive its motor depending on the threshold.\n\n\nMCU Peripherals"
  },
  {
    "objectID": "deliverables/midpoint.html",
    "href": "deliverables/midpoint.html",
    "title": "Project Midpoint Report",
    "section": "",
    "text": "As of the midpoint report being written, the team has accomplished the following: - Configuration of the OV7670 camera module through register writes from the MCU over an I2C interface - Pixel data capture from the OV7670 camera module on the FPGA - Streaming bit-masked pixel data from the FPGA to the MCU over a 1-directional parallel bus - Full bit-masked frame capture and display on the MCU using GPIO polling\nAs a reminder, the overall specs for the project are listed below, with the already-completed specs checked off.\n\nRobot follows a black line on white paper\nRobot doesn’t move if both cameras see a black line\nRobot uses camera as vision interface\nFPGA receives pixel data from OV7670\nFPGA sends masked frame data to MCU over a communication interface\nMCU configures registers on OV7670 over SCCB/I2C interface\nMCU is able to receive full frames from FPGA\n\nAt this point in the project, the team believes that the riskiest elements have been completed, as the camera is now able to be configured, and camera data is captured by the FPGA, analyzed, and sent to the MCU.\n\n\n\nPrior to beginning work on the project, the team identified the riskiest element as configuring the OV7670 CMOS camera using the MCU over the SCCB interface. This was because there weren’t many examples on how to implement this interface, which created the possibility of the team needing to bit-bang our own SCCB interface, which is similar to I2C but has some quite relevant differences, the main one being that the SCCB controller on the OV7670 sends a “don’t care” bit as the 9th bit, while the I2C interface on the MCU expects an “ACK” bit to be sent from the OV7670 to acknowledge data. However, the team was succesfully able to configure the OV7670 using the I2C peripheral on the MCU.\n\n\n\nNow that the team is receiving full frames on the MCU, the remaining work can be broken into three phases.\n\n\nCurrently, the FPGA sends the MCU a pixel as soon as it finishes bit-masking it. For the final design, the goal will be to implement an asynchronous FIFO using the SPRAM on the MCU, so that full frames can be read much quicker, leaving time for robot control.\n\n\n\nAlthough the team has purchased a robot kit, some design considerations need to be taken into account, as the camera needs to be mounted on the robot along with the rest of the parts. The camera module will likely need a light mounted near it to illuminate the track, which would also require the integration of a lens hood.\n\n\n\nOnce the peripherals are fully integrated and mounted on the robot chassis, the team expects that there will be significant work left to do on tuning the control system on the MCU, as well as tuning camera exposure settings to improve line recognition. Also, the field of view of the camera will need to be determined, and the camera will potentially need to be focused."
  },
  {
    "objectID": "deliverables/midpoint.html#progress-report",
    "href": "deliverables/midpoint.html#progress-report",
    "title": "Project Midpoint Report",
    "section": "",
    "text": "As of the midpoint report being written, the team has accomplished the following: - Configuration of the OV7670 camera module through register writes from the MCU over an I2C interface - Pixel data capture from the OV7670 camera module on the FPGA - Streaming bit-masked pixel data from the FPGA to the MCU over a 1-directional parallel bus - Full bit-masked frame capture and display on the MCU using GPIO polling\nAs a reminder, the overall specs for the project are listed below, with the already-completed specs checked off.\n\nRobot follows a black line on white paper\nRobot doesn’t move if both cameras see a black line\nRobot uses camera as vision interface\nFPGA receives pixel data from OV7670\nFPGA sends masked frame data to MCU over a communication interface\nMCU configures registers on OV7670 over SCCB/I2C interface\nMCU is able to receive full frames from FPGA\n\nAt this point in the project, the team believes that the riskiest elements have been completed, as the camera is now able to be configured, and camera data is captured by the FPGA, analyzed, and sent to the MCU.\n\n\n\nPrior to beginning work on the project, the team identified the riskiest element as configuring the OV7670 CMOS camera using the MCU over the SCCB interface. This was because there weren’t many examples on how to implement this interface, which created the possibility of the team needing to bit-bang our own SCCB interface, which is similar to I2C but has some quite relevant differences, the main one being that the SCCB controller on the OV7670 sends a “don’t care” bit as the 9th bit, while the I2C interface on the MCU expects an “ACK” bit to be sent from the OV7670 to acknowledge data. However, the team was succesfully able to configure the OV7670 using the I2C peripheral on the MCU.\n\n\n\nNow that the team is receiving full frames on the MCU, the remaining work can be broken into three phases.\n\n\nCurrently, the FPGA sends the MCU a pixel as soon as it finishes bit-masking it. For the final design, the goal will be to implement an asynchronous FIFO using the SPRAM on the MCU, so that full frames can be read much quicker, leaving time for robot control.\n\n\n\nAlthough the team has purchased a robot kit, some design considerations need to be taken into account, as the camera needs to be mounted on the robot along with the rest of the parts. The camera module will likely need a light mounted near it to illuminate the track, which would also require the integration of a lens hood.\n\n\n\nOnce the peripherals are fully integrated and mounted on the robot chassis, the team expects that there will be significant work left to do on tuning the control system on the MCU, as well as tuning camera exposure settings to improve line recognition. Also, the field of view of the camera will need to be determined, and the camera will potentially need to be focused."
  },
  {
    "objectID": "deliverables/midpoint.html#documentation",
    "href": "deliverables/midpoint.html#documentation",
    "title": "Project Midpoint Report",
    "section": "Documentation",
    "text": "Documentation\n\nSchematic\nThe team has created a semi-finalized schematic representing all the connections between the different peripherals in the system, which can be seen below.\n\n\n\nSchematic\n\n\n\n\nBlock Diagram\nThe block diagram has been updated slightly since the proposal to reflect some of the changes in the design methodology.\n\n\n\nBlock Diagram\n\n\n\n\nMCU Routine Overview\nCurrently, the MCU uses a super loop and polling to capture frame data. Eventually, the hope is to use FreeRTOS, although that is not a spec for the project because it’s a stretch goal. The current routine involves waiting for the frame-active pin to go high, then reading pixel data on the falling edge of PCLK when the pixel data is valid. The pixel data is currently stored in RAM on the MCU, as each frame is only 9.6kB, so one frame can be stored in RAM at a time. Once the asynchronous FIFO has been implemented on the FPGA, the entire frame will be streamed to the MCU, so the MCU will not need to check whether the data is valid. When combined with DMA for frame capture, this will allow for much faster frame reads and will decrease the amount of dropped frames.\n\n\nFPGA Code\n\n\n\n\n\n\nNote(Click to expand)\n\n\n\n\n\n\n\n\n\n\n\nMCU Code\n\n\n\n\n\n\nNote(Click to expand)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "References",
    "section": "",
    "text": "References\n\nSource code github repository\nSTM32L432KC Reference Manual\nOV7670 Datasheet\nOV7670 Implementation Guide\n\n\n\nAcknowledgements\nThanks to everyone who made this project possible!\n\nTo Leilani Elkaslasy, who generously gave us her board when we fried an FPGA at 3 am the day before checkoff.\nTo Prof. Spencer, for stepping in and teaching MicroPs in such a large class year.\nTo Xavier Walter, who provided constant support throughout the project.\nTo Jacob Staimpel, for his help in procuring all the random nuts and bolts used during the mechanical design process."
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "fpga.html",
    "href": "fpga.html",
    "title": "FPGA Overview",
    "section": "",
    "text": "The project uses two FPGAs, each of which is independent from the other. The FPGA’s purpose is to capture the raw pixel data in YUV422 QVGA format from the OV7670 camera, and then store the bitmasked frame of Y-values of pixel data based on a pre-determined threshold by the user. This bitmasked image is stored in SPRAM frame buffer in the FPGA, before being sent to the MCU over SPI.\nSystem Architecture:\nOV7670 Camera → Threshold Module → Frame Buffer → Serial Interface → MCU\n(YUV422 QVGA) (Y-only, 1-bit/pixel)  (SPRAM)         (SPI)"
  },
  {
    "objectID": "fpga.html#general-overview",
    "href": "fpga.html#general-overview",
    "title": "FPGA Overview",
    "section": "",
    "text": "The project uses two FPGAs, each of which is independent from the other. The FPGA’s purpose is to capture the raw pixel data in YUV422 QVGA format from the OV7670 camera, and then store the bitmasked frame of Y-values of pixel data based on a pre-determined threshold by the user. This bitmasked image is stored in SPRAM frame buffer in the FPGA, before being sent to the MCU over SPI.\nSystem Architecture:\nOV7670 Camera → Threshold Module → Frame Buffer → Serial Interface → MCU\n(YUV422 QVGA) (Y-only, 1-bit/pixel)  (SPRAM)         (SPI)"
  },
  {
    "objectID": "fpga.html#ov7670-camera-pixel-capture-and-bitmasking",
    "href": "fpga.html#ov7670-camera-pixel-capture-and-bitmasking",
    "title": "FPGA Overview",
    "section": "OV7670 Camera Pixel Capture and Bitmasking",
    "text": "OV7670 Camera Pixel Capture and Bitmasking\n\nYUV422 Format and Y-value (luminosity) of pixel extraction\nThe OV7670 camera supports sending data in multiple formats, but for our project, as we realized we only care about differentiating between two colours of the lines and the track, we could easily do this by using YUV format output, and just using the Y values of the pixel data which represent the luminosity, while ignoring the U/V values which encode the chroma/colour data. Given we chose black line on white background for our testing purposes, using Y values would be sufficient, as they would have different intensity levels.\nYUV422 Data Format:\nThe YUV data sent by the camera is in the format of 8-bit Y, 8-bit U or 8-bit Y, 8-bit V, therefore, we only care about every other byte of pixel data which represent the Y values for all the 76,800 pixels we receive in the QVGA format.\nData Stream:     Y0  U0  Y1  V0  Y2  U1  Y3  V1 ...\nBytes Captured:  Y0  --  Y1  --  Y2  --  Y3  -- ...\nThis also helps us save lot of memory as we reduce the frame data by 94%\n\nFull YUV422: 76,800 pixels × 2 bytes = 153,600 bytes\nY-only binary: 76,800 pixels × 1 bit = 9,600 bytes\n\n\n\nThreshold Module Operation\nThe camera_capture_threshold module runs entirely in the camera pixel clock domain and processes incoming YUV422 data in real-time.\nKey Signals:\n// Inputs\ncam_pclk:   Pixel clock from OV7670\ncam_vsync:  Frame sync (LOW = active frame)\ncam_href:   Line valid (HIGH = pixel data valid)\ncam_data:   8-bit YUV422 data bus\nthreshold:  8-bit comparison value (our chosen value 141)\n\n// Outputs\nwr_addr:    17-bit pixel address (0-76,799)\nwr_data:    1-bit thresholded result (bright/dark)\nwr_en:      Write enable pulse\nframe_done: Frame complete pulse\nOperation:\nThe module uses a priority-based control structure with four operations:\n\nFrame Start (VSYNC falling edge) - Reset counters, begin capture\nFrame End (VSYNC rising edge) - Signal completion\nPixel Capture (during frame with HREF valid) - Threshold and write Y bytes\nEnd of Line (HREF falling edge) - Reset line counters\n\nByte Selection Logic:\nA simple toggle mechanism parses the YUV422 stream:\nif (byte_select == 0) begin      // Y byte\n    wr_en   &lt;= 1;\n    wr_data &lt;= (data &gt; threshold);\n    byte_select &lt;= 1;            // Next is U/V\nend else begin\n    byte_select &lt;= 0;            // Skip U/V, next is Y\nend\nThis alternates between capturing Y bytes (luminance) and skipping U/V bytes (chroma)."
  },
  {
    "objectID": "fpga.html#spram-frame-buffer-and-spi-transfer",
    "href": "fpga.html#spram-frame-buffer-and-spi-transfer",
    "title": "FPGA Overview",
    "section": "SPRAM Frame Buffer and SPI Transfer",
    "text": "SPRAM Frame Buffer and SPI Transfer\n\nMemory Architecture\nThe iCE40 UP5K provides 128 KB of SPRAM (Single-Port RAM), which we use for double-buffered frame storage:\n\nEach frame: 76,800 bits = 4,800 words (16 bits/word)\nBank 0: Addresses 0x0000-0x12BF\nBank 1: Addresses 0x1300-0x257F\nTotal usage: 9,600 words (~15% of SPRAM capacity)\n\n\n\nBit Packing\nSince the threshold module outputs 1 bit per pixel, data is packed into 16-bit words:\nPixel Address [16:0]:\n  Bits [16:4] → Word address (0-4,799)\n  Bits [3:0]  → Bit position (0-15)\nWhen 16 bits accumulate in the camera domain, they’re latched and transferred to the system clock domain (48 MHz) for SPRAM write.\n\n\nDouble Buffering (Ping-Pong)\nThe frame buffer uses ping-pong buffering to enable simultaneous camera write and MCU read:\n\nCamera writes to Bank A, MCU reads from Bank B\nOn frame completion, banks swap roles\nCamera immediately starts writing to Bank B\nMCU continues reading completed Bank A\nProcess repeats continuously\n\nThis ensures no frame drops at 30 fps, even if the MCU lags behind by one frame.\n\n\nClock Domain Crossing (CDC)\nThe system operates across two asynchronous clock domains:\n\nCamera domain: ~2.5 MHz (from OV7670)\nSystem domain: 48 MHz (internal oscillator)\n\nAll cross-domain signals use 3-stage synchronizers to prevent metastability:\n// Example: Write request crossing\nalways @(posedge r_clk) begin\n    w_req_sync &lt;= {w_req_sync[1:0], w_req_toggle};\nend\nData is latched in the source domain before the control signal toggles, ensuring stability during crossing.\n\n\nSerial Interface to MCU\nThe FPGA implements a SPI slave interface:\nProtocol:\n\nFPGA asserts frame_ready when new frame available\nMCU generates SCK pulses (3-48 MHz recommended)\nFPGA outputs one bit per SCK falling edge\nAfter 76,800 bits, FPGA deasserts frame_ready\n\nThe module uses priority-based logic:\n\nNew frame event - Reset address, load first word from SPRAM\nLoad complete - Capture SPRAM data into shift register\nShift on MCU clock - Output bits serially, fetch next word when needed\n\nTiming:\nAt 10 MHz SCK: 76,800 bits / 10 MHz = 7.68 ms per frame\nCamera frame period: 33.33 ms (30 fps)\n\n\nPin Count\n\nCamera interface: 11 pins (pclk, vsync, href, data[7:0])\nMCU interface: 3 pins (sck, mosi, frame_ready)\nSystem: 1 pin (reset)\nTotal: 14 I/O pins"
  },
  {
    "objectID": "fpga.html#performance-summary",
    "href": "fpga.html#performance-summary",
    "title": "FPGA Overview",
    "section": "Performance Summary",
    "text": "Performance Summary\nCamera Capture: - Frame rate: 30 fps - Pixel rate: 2.3 Mpixels/sec - Bit rate: 2.3 Mbits/sec (after thresholding)"
  },
  {
    "objectID": "fpga.html#testing-results",
    "href": "fpga.html#testing-results",
    "title": "FPGA Overview",
    "section": "Testing Results",
    "text": "Testing Results\nThe system has been validated with:\n\nContinuous frame capture at QVGA resolution\nCorrect YUV422 byte selection (Y-only)\nThreshold discrimination (black line detection)\nBank swapping without corruption\nProper Serial readout over SPI\n\nThe hardware has been tested extensively and performs reliably in the line-following application."
  },
  {
    "objectID": "deliverables.html",
    "href": "deliverables.html",
    "title": "Early Deliverables",
    "section": "",
    "text": "Project Final Checkoff Report\n\n\nProject Final Checkoff Report\n\n\n\n\n\nDec 3, 2025\n\n\nAabhas Senapati & Diego Weiss\n\n\n\n\n\n\n\n\n\n\n\n\nProject Midpoint Report\n\n\nProject Midpoint Report\n\n\n\n\n\nNov 20, 2025\n\n\nAabhas Senapati & Diego Weiss\n\n\n\n\n\n\n\n\n\n\n\n\nProject Proposal\n\n\nProject Proposal\n\n\n\n\n\nOct 15, 2025\n\n\nAabhas Senapati & Diego Weiss\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Robot Site",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "deliverables/checkoff.html",
    "href": "deliverables/checkoff.html",
    "title": "Project Final Checkoff Report",
    "section": "",
    "text": "One Pager\nAs a reminder, the overall specs for the project are listed below. All specs were completed!\n\nRobot follows a black line on white paper\n\nThis spec essentially encapsulates the project, and was confirmed through visual observation of the final robot.\n\nRobot doesn’t move if both cameras see a black line\n\nThis spec was confirmed by observing the performance of the robot.\n\nRobot uses camera as vision interface\n\nThe only sensors being used to control the robot are cameras. Due to difficulties encountered with camera noise, two cameras are used to control the robot, with control determined by the amount of black pixels in each image.\n\nFPGA receives pixel data from OV7670\n\nThe FPGA receiving pixel data from the OV7670 was confirmed through the performance of our system. It was difficult to verify the design worked in the real world until we had our MCU configured to receive data from the FPGA, but once we did, we were able to confirm that the MCU received changing pixel data from the FPGA, which told us that the FPGA was receiving pixel data from the OV7670. Otherwise, we wouldn’t be able to see the difference between black and white!\n\nFPGA sends masked frame data to MCU over a communication interface\n\nThe FPGA sends frames to the MCU over a modified SPI bus, where the MCU is configured as the master. Because the communication between the FPGA and MCU is one-directional, only the COPI and CLK lines were connected. The MCU recevies a signal from the FPGA indicating that a frame is ready to be sent. Once it receives that signal, it sends the SPI CLK to the FPGA, and the FPGA shifts data out over that clock.\n\nMCU configures registers on OV7670 over SCCB/I2C interface\n\nWe were able to confirm that the MCU configures registers on the OV7670 early on in the project. SCCB effectively acts as I2C, but is named differently for licensing reasons. Using the MCU’s I2C peripheral, we were able to write to specific registers and then read back those registers to confirm succesful writes.\n\nMCU is able to receive full frames from FPGA\n\nWe know that the MCU receives full frames from the FPGA (within some tolerance), because the control loop includes a condition that the MCU doesn’t control the motor it’s connected to unless it receives at least 76000 pixels from the FPGA. This is actually a critical function for robot control, as if we controlled off partial frames, the robot’s performance would likely suffer.\n\n\n\n\nSchematic\nThe final system schematic representing all the connections between the different peripherals in the system can be seen below.\n\n\n\nSchematic\n\n\n\n\nBlock Diagram\nThe team produced a block diagram describing our RTL, which can be seen below.\n\n\n\nBlock Diagram\n\n\n\n\nCode\nThe source code for the final project can be found in the team’s Github repository"
  },
  {
    "objectID": "deliverables/proposal.html",
    "href": "deliverables/proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "The inspiration for this project came from a project Diego completed in a robotics class during his junior year of high school. He built an extremely rudimentary line-follower robot using an Arduino and two IR sensors. The goal of this project is to once again build a line-follower robot, this time interfacing an OV7670 camera with an UPduino iCE40 UP5K FPGA board (“the FPGA”) and a STM32L432KC microcontroller (“the MCU”). The FPGA will interface with the OV7670 to detect the line and send the resultant information to the MCU for robot control."
  },
  {
    "objectID": "deliverables/proposal.html#project-design-overview",
    "href": "deliverables/proposal.html#project-design-overview",
    "title": "Project Proposal",
    "section": "",
    "text": "The inspiration for this project came from a project Diego completed in a robotics class during his junior year of high school. He built an extremely rudimentary line-follower robot using an Arduino and two IR sensors. The goal of this project is to once again build a line-follower robot, this time interfacing an OV7670 camera with an UPduino iCE40 UP5K FPGA board (“the FPGA”) and a STM32L432KC microcontroller (“the MCU”). The FPGA will interface with the OV7670 to detect the line and send the resultant information to the MCU for robot control."
  },
  {
    "objectID": "deliverables/proposal.html#specifications",
    "href": "deliverables/proposal.html#specifications",
    "title": "Project Proposal",
    "section": "Specifications",
    "text": "Specifications\n\nRobot follows a black line on white paper\nRobot doesn’t move if no line is detected\nRobot uses camera as vision interface\nFPGA receives pixel data from OV7670\nFPGA sends masked pixel data to MCU over a communication interface\nMCU configures registers on OV7670 over SCCB/I2C interface\nMCU is able to receive full frames from FPGA"
  },
  {
    "objectID": "deliverables/proposal.html#design-details",
    "href": "deliverables/proposal.html#design-details",
    "title": "Project Proposal",
    "section": "Design Details",
    "text": "Design Details\n\nMCU Design & New Functionality\nThe MCU will have four critical functions. It needs to configure the OV7670 over the SCCB interface, send the FPGA a signal to drive XCLK, read bit-masked frames from the FPGA over SPI, and control the position of the robot along the line based on the data from the frames. The new functionality on the MCU will be the SCCB peripheral and the implementation of DMA to enable high-speed SPI reads.\n\n\nFPGA Design & New Functionality\nThe FPGA has several critical functions, notably to: drive XCLK at 24MHz, read & process pixel data from the OV7670, and communicate that data to the MCU over SPI. In order to send pixel data to the MCU, a double SPRAM buffer will be implemented. The new functionality on the FPGA will be the SPRAM buffer and SPI communication.\n\n\nNew Hardware\nThe main piece of new hardware being integrated is the OV7670 camera module.\n\n\nRiskiest Element\nUsing the MCU to configure the OV7670 is definitely the riskiest element of the project. Although the SCCB interface is based on I2C, literature review indicated that the I2C interface on the MCU would not be able to configure the camera. So, the team will need to bit-bang an SCCB interface. The team will attempt to mitigate risk by consulting examples available online."
  },
  {
    "objectID": "deliverables/proposal.html#technical-documentation",
    "href": "deliverables/proposal.html#technical-documentation",
    "title": "Project Proposal",
    "section": "Technical Documentation",
    "text": "Technical Documentation\n\nBlock Diagram\n\n\n\n\n\n\nFigure 1: Block Diagram\n\n\n\nThe block diagram in Figure 1 provides a general outline of the protocols and interfaces that will be utilized in the project.\n\n\nPerformance Calculations\n\nSPI Performance\nAccording to the datasheet of the STM32, the maximum frequency of SCK when configured in master/receiver full-duplex mode is 40MHz when VDD ∈ [2.7, 3.6]. A 40 MHz SCK results in a maximum throughput of approximately 5 MB/s. Since each frame will be 9.6kB, each frame can be read in approximately 1.92ms. For a frame rate of 30 fps, the FPGA will produce a frame every 33.3ms. This means that there will be approximately 31.3 ms for robot control.\n\n\nLUT Usage\nThese are meant to be preliminary order-of-magnitude calculations. The FPGA used (Lattice iCE40 UP5K) has hardware SPI support, so the SPI interface requires no LUTs.\n\nAssuming 8 8-bit counters for things like write address, read address, frame ID, etc, we have 64 LUTs\nFor bit masking, a comparator can be used. If we compare on all 8 bits of the Y (using a YUV pixel format), we’d need 8 LUTs\nTo encode the double buffer, we’d need enough LUTs for state. If we assume 20 states (massive overestimate), we’d at most 100 LUTs.\nTo account for any other random parts of the design, we’ll add in 200 extra LUTs\n\nThis only brings us &lt;400 LUTs. Although we likely missed aspects of the design, it is exceedingly unlikely that we come close to even 40% LUT resource usage on the FPGA, as the FPGA has ~5000 LUTs available\n\n\nSPRAM Buffer Sizing\nAccording to the datasheet for the FPGA, we have 1 MB of SPRAM available. A 1-bit mask of a QVGA image only requires 9.6kB of space. So, we have more than enough space in SPRAM."
  },
  {
    "objectID": "deliverables/proposal.html#project-management",
    "href": "deliverables/proposal.html#project-management",
    "title": "Project Proposal",
    "section": "Project Management",
    "text": "Project Management\n\nBill of Materials\n\n\n\n\n\n\n\n\n\n\nItem\nPart Number\nQuantity\nPrice\nSource\n\n\n\n\nCamera Module\nOV7670\n1\n$8-12 (+ shipping)\nAmazon\n\n\nPotentiometer (Threshold control)\n10 k \\(\\Omega\\) Linear Pot\n1\nStockroom\nStockroom\n\n\nDC Motors\nTT Gear Motor (3-6 V)\n2\nStockroom\nStockroom\n\n\nMotor Driver\nL298N\n1\n$3-6\nAmazon/Stockroom\n\n\nRobot Chassis Kit\nN/A\n1\nStockroom\nStockroom\n\n\n\n\n\nProject Timeline\n\n\n\nTask(s)\nDate\n\n\n\n\nFinish proposal\n10/20/25\n\n\nStart Project\n10/21/25\n\n\nPrepare slides for design review\n11/7/25\n\n\nFinish Midpoint Report & Demo\n11/16/25\n\n\nFinal Checkoff\n12/5/25\n\n\nFinal Report Due\n12/7/25\n\n\nDemo Day\n12/8/25\n\n\n\n\n\nTask Delegation\n\n\n\nDiego\nAabhas\n\n\n\n\nStart MCU Code\nStart FPGA Code\n\n\nCheck FPGA Code\nCheck MCU Code\n\n\nDecide MCU task scheduling\nDecide MCU task scheduling\n\n\nWrite robot control code\nCheck robot control code\n\n\nCheck robot\nAssemble robot\n\n\nWrite verification\nWrite verification\n\n\nWrite documentation\nWrite documentation\n\n\n\nOur aim is to work together as much as possible, so that both team members are full owners of the project."
  }
]